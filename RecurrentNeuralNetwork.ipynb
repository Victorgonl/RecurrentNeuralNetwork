{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uma breve introdução às Redes Neurais Recorrentes (RNN - Recurrent Neural Network)\n",
    "\n",
    "### Universidade Federal de Lavras - Agosto de 2022\n",
    "* Elaborado por: Victor Gonçalves Lima\n",
    "* Orientado por: Prof. Dr. Denilson Alves Pereira"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dados sequenciais (sequential data):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propriedades:\n",
    "\n",
    "* A sequência pode conter elementos repetidos\n",
    "\n",
    "* É sensível ao contexto\n",
    "\n",
    "* O tamanhos dos dados varia\n",
    "\n",
    "## Exemplos:\n",
    "\n",
    "* Textos\n",
    "\n",
    "* Audio (voz e música)\n",
    "\n",
    "* Vídeos\n",
    "\n",
    "* Séries de dados\n",
    "\n",
    "* Sequência de DNA\n",
    "\n",
    "## Language models\n",
    "\n",
    "* Generative model\n",
    "\n",
    "* N-grams\n",
    "\n",
    "* Context vectorizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vetorização de contexto (context vectorizing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* É um método onde os dados da sequência é dividida em um vetor.\n",
    "\n",
    "<img src=\"figs/Context-vectorizing.png\" width=\"400\" title=\"https://neptune.ai/blog/recurrent-neural-network-guide\"/>\n",
    "\n",
    "#### Vantagens:\n",
    "\n",
    "* A ordem é preservada\n",
    "* Funciona para entradas de diferentes tamanhos\n",
    "* Pode ser aplicado ***backpropagation*** e assim aprender\n",
    "* O contexto é presenvado para sentenças curtas ou texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquitetura das Redes Neurais Recorrentes (RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Por conta de suas propriedades, dados sequenciais não funcionam bem com ***feed-forward networks***, que por definição trabalha com entradas de tamanho fixo.\n",
    "\n",
    "* RNN são modelos usados para trabalhar com ***dados sequenciais*** incorporando a técnica de ***vetorização de contexto***.\n",
    "\n",
    "* A vetorização permite que as RNNs busque informações passadas já calculadas ao longo da sequencia, assim, as RNNs permitem a entrada de múltiplos vetores, produzindo uma mais mais saídas vetoriais.\n",
    "\n",
    "* De uma forma simplificada, RNN são redes neurais com loops, permitindo que as informações anteriores sejam preservadas.\n",
    "\n",
    "<img src=\"figs/RNN-rolled.png\" width=\"150\" title=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/\"/>\n",
    "\n",
    "* Desenrolando este loop, verificamos que a RNN se apresenta como múltiplas cópias da mesma rede, cada uma passando a informação para um sucessor.\n",
    "\n",
    "<img src=\"figs/RNN-unrolled.png\" width=\"800\" title=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time step *t*\n",
    "* Nas RNN, *x(t)* é uma entrada na rede em um paço de tempo *t*, utilizado para indicar a ordem que uma palavra, por exemplo, ocorre na sequência."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden state *h(t)*\n",
    "\n",
    "* Um *h(t)* representa um ***vetor contextual*** em um tempo *t* e age como uma \"mémoria\" da rede.\n",
    "\n",
    "* O ***vetor contextual*** *h(t)* é calculado a partir da entrada atual *x(t)* e da entrada em uma unidade de tempo *t* anterior da ***hidden state*** *h(t-1)*.\n",
    "\n",
    "* $h_{t} = tanh(W_{h}h_{t-1} + W_{x}x_{t})$\n",
    "\n",
    "#### Compartilhamento de parâmetros (parameter sharing)\n",
    "\n",
    "* Os parametros $\\{W_{h}, W_{x}, W_{y}\\}$ são constantes para todas as entradas da rede, permitindo que as RNN mantenham a informação contextual mesmo com variações no tamanho da sentança de entrada.\n",
    "\n",
    "<img src=\"figs/Recurrent-neural-network.png\" width=\"200\" title=\"https://neptune.ai/blog/recurrent-neural-network-guide\"/>\n",
    "\n",
    "* RNNs compartilham os mesmos parâmetros por várias unidades de tempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predição\n",
    "\n",
    "* A predição de uma RNN será a saída do último ***hiden state*** junto ao parâmetro de saída $W_{y}$\n",
    "\n",
    "* Tal predição é similar a um ***problema de classificação***, e então uma função ***softmax*** é aplicada a fim de prever a saída ideal de acordo com as possiblidades."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinando RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computando os gradientes\n",
    "\n",
    "* Durante o ***backpropagation***, a rede deve voltar cada paço de tempo para atualizar os parâmetros.\n",
    "\n",
    "* Como prever a saída de uma RNN é um ***problema de classificação***, é utilizado ***cross-entropy*** para calcular a perda.\n",
    "\n",
    "* **Cross-entropy:** $L_{θ}(y,y’)_{t} = -y+{t}\\log{y_{t}'}$, onde $θ = \\{Wh,Wx,Wy\\}$.\n",
    "\n",
    "## Backpropagation through time (BPTT)\n",
    "\n",
    "* A rede precisa ser desenrolada para que seus parâmetros sejam diferenciados pela rede respeitando o ***time step***.\n",
    "\n",
    "* Como a rede pega uma palavra por vez, o cálculo da perda é baseado por cada palavra.\n",
    "\n",
    "<img src=\"figs/Backpropagation.png\" width=\"400\" title=\"https://neptune.ai/blog/recurrent-neural-network-guide\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problemas com as RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As aplicações de RNN utilizam o contexto para executar sua tarefa.\n",
    "\n",
    "<img src=\"figs/RNN-shorttermdepdencies.png\" width=\"500\" title=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/\"/>\n",
    "\n",
    "* Quanto maior a distância entre o contexto para a saída, mais difícil será para a RNN conectar a informação necessária.\n",
    "\n",
    "<img src=\"figs/RNN-longtermdependencies.png\" width=\"600\" title=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Vanishing gradients\n",
    "\n",
    "## Exploding gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long Short Term Memory (LSTM)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
